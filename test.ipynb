{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.ops import sigmoid_focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.rand(2, 30)\n",
    "target = torch.randint(0, 2, (2,30), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = sigmoid_focal_loss(output, target, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1404)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_with_head(nn.Module):\n",
    "    def __init__(self, config, device):\n",
    "        super(QA_with_head, self).__init__()\n",
    "\n",
    "        self.config = config \n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(self.config.model.model_path)\n",
    "        if config.model.two_step_loss:\n",
    "            self.score=nn.Linear(config.model.dim,1)\n",
    "            self.loss_fct=nn.BCEWithLogitsLoss()\n",
    "        self.classifier_hidden = torch.nn.Linear(128, 128)\n",
    "        self.classifier_dropout = torch.nn.Dropout(p=0.2)\n",
    "        self.output_layer = torch.nn.Linear(128, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.loss_classifier = torch.nn.BCELoss()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, batch):\n",
    "        if not self.config.model.non_pooler:\n",
    "            out = self.model(input_ids = batch[\"question_context_input_ids\"].to(self.device), \n",
    "                            attention_mask = batch[\"question_context_attention_mask\"].to(self.device),\n",
    "                            token_type_ids = batch[\"question_context_token_type_ids\"].to(self.device),\n",
    "                            start_positions = batch[\"start_positions\"].to(self.device),\n",
    "                            end_positions = batch[\"end_positions\"].to(self.device),\n",
    "                            output_hidden_states=True)\n",
    "        else:\n",
    "            out = self.model(input_ids = batch[\"question_context_input_ids\"].to(self.device), \n",
    "                            attention_mask = batch[\"question_context_attention_mask\"].to(self.device),\n",
    "                            start_positions = batch[\"start_positions\"].to(self.device),\n",
    "                            end_positions = batch[\"end_positions\"].to(self.device),\n",
    "                            output_hidden_states=True)\n",
    "        if self.config.model.two_step_loss:\n",
    "            cls_tokens=out.hidden_states[-1][:,0]\n",
    "            scores=self.score(cls_tokens) # [32,1]\n",
    "            out.loss+=self.loss_fct(scores,batch[\"answerable\"])\n",
    "\n",
    "            return (out,torch.nn.functional.softmax(scores))\n",
    "\n",
    "        if out.loss != None :\n",
    "            cls_representations = out[\"hidden_states\"][-1][:, 0, :]\n",
    "            cls_representations = self.classifier_hidden(cls_representations)\n",
    "            cls_representations = self.classifier_dropout(cls_representations)\n",
    "            cls_representations = self.output_layer(cls_representations)\n",
    "            cls_representations = cls_representations.squeeze(dim=-1)\n",
    "            cls_representations = self.sigmoid(cls_representations)\n",
    "            answerable = torch.tensor(batch[\"answerable\"],dtype = torch.float32)\n",
    "            clf_loss = self.loss_classifier(cls_representations, answerable)\n",
    "            out.loss += clf_loss\n",
    "\n",
    "        return out  \n",
    "\n",
    "    def export_to_onnx(self, tokenizer):\n",
    "        # TODO Using torch.onnx.export\n",
    "        # Will use transformers.onnx.export for transformer models\n",
    "\n",
    "        # TODO Using transformers.onnx if this doesn't work\n",
    "        feature = \"question-answering\"\n",
    "\n",
    "        # load config\n",
    "        model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(self.model, feature=feature)\n",
    "        onnx_config = model_onnx_config(self.model.config)\n",
    "\n",
    "        # export\n",
    "        onnx_inputs, onnx_outputs = transformers.onnx.export(\n",
    "                preprocessor=tokenizer,\n",
    "                model=self.model,\n",
    "                config=onnx_config,\n",
    "                opset=13,\n",
    "                output=Path(\"checkpoints/{}/model.onnx\".format(self.config.load_path))\n",
    "        )\n",
    "\n",
    "        print(onnx_inputs, onnx_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many programming languages does BLOOM support?\"\n",
    "context = \"BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 382/382 [00:00<00:00, 164kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:03<00:00, 70.6kB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([question, question], [context, context], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2129,  2116,  4730,  4155,  2515, 13426,  2490,  1029,   102,\n",
       "         13426,  2038, 18561,  4551, 11709,  1998,  2064,  9699,  3793,  1999,\n",
       "          4805,  4155,  3019,  4155,  1998,  2410,  4730,  4155,  1012,   102],\n",
       "        [  101,  2129,  2116,  4730,  4155,  2515, 13426,  2490,  1029,   102,\n",
       "         13426,  2038, 18561,  4551, 11709,  1998,  2064,  9699,  3793,  1999,\n",
       "          4805,  4155,  3019,  4155,  1998,  2410,  4730,  4155,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd66cb49a841fcb800c6001c710cf6a2c3702cb7d0b679bebfede6c97481890d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
