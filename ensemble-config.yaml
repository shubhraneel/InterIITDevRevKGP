task: qa
seed: 3407
wandb_path: ensemble-testing
fewshot_qa: False
inference_device: cuda
train: False
inference: False
save_model_optimizer: False
load_model_optimizer: True
load_path: ensemble-testing
use_drqa: True
create_drqa_tfidf: False
top_k: 5
scheduler: "linear"
sentence_level: True
two_level_drqa: False
quantize: False
ONNX: False
create_dense_embeddings: True
retriever_type: dense # dense or tfidf
create_inf_table: False
ensemble: True
ensemble_load_paths:
  - v2-bert-experiments-5
  - v2-bert-experiments-5

data:
  train_data_path: data-dir/train/df_train.pkl
  val_data_path: data-dir/val/df_val.pkl
  test_data_path: data-dir/test/df_test.pkl
  train_batch_size: 16
  val_batch_size: 2
  apply_aliasing: False
  pad_on_right: True
  max_length: 512
  doc_stride: 0
  tokenizer_batch_size: 32
  answer_max_len: 10

training:
  epochs: 10
  optimizer: adam
  lr: 0.00002
  sched_function: none
  sched_func_params: {}
  sched_params:
    monitor: val_loss
  evaluate_every: 1
  lr_flag : False
  can_loss: False  # Contrastive_Adaptive_Loss
  can_loss_beta: 0.01  # 0.00000001
  
model:
  model_path: google/bert_uncased_L-4_H-128_A-2
  params: {}
  non_pooler: False
  noise_tuner: False
  noise_lambda: 0.15
  non_pooler: False
  dim: 128
  span_level: False
  two_step_loss: False
  span_level: False

ensemble_models:
  - model_path: google/bert_uncased_L-4_H-128_A-2
    params: {}
    non_pooler: False
    noise_tuner: False
    noise_lambda: 0.15
    non_pooler: False
    dim: 128
    span_level: False
    two_step_loss: False
    span_level: False
  - model_path: google/bert_uncased_L-4_H-128_A-2
    params: {}
    non_pooler: False
    noise_tuner: False
    noise_lambda: 0.15
    non_pooler: False
    dim: 128
    span_level: False
    two_step_loss: False
    span_level: False
