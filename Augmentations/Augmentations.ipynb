{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8xHRryePDyzi",
        "Sw0OpaM1EWg3",
        "lTvl7aEKhSR_",
        "KrGQkcUwkhHV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8hTHi54UCuy",
        "outputId": "f12ef742-4b83-4a5e-ce8f-27f1b2140bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/InterIIT_Tech_Meet_Abhranil_Exp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmsyikpqaOTc",
        "outputId": "89cfd099-51be-46ab-cded-c09b69dd21dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/InterIIT_Tech_Meet_Abhranil_Exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjVS1pPlbTTO",
        "outputId": "15ae4d1c-233e-43fd-8e85-b3c42ce9c0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Adv Example via Augmentations.ipynb'\n",
            " Bert_Training_on_TopDrQAContext.ipynb\n",
            " char_swap_fin.csv\n",
            " \u001b[0m\u001b[01;34mdata-dir\u001b[0m/\n",
            " DataManipulation.ipynb\n",
            " Data_Split.ipynb\n",
            " df_test.csv\n",
            " df_test.pkl\n",
            " df_train.csv\n",
            " df_train.pkl\n",
            " df_val.csv\n",
            " df_val.pkl\n",
            " \u001b[01;34mdomain_divergence\u001b[0m/\n",
            " \u001b[01;34mInterIITDevRevKGP\u001b[0m/\n",
            "\u001b[01;34m'Orig Data plus Easy Aug'\u001b[0m/\n",
            " \u001b[01;34mPretrained_LM\u001b[0m/\n",
            " \u001b[01;34mR-GCN\u001b[0m/\n",
            " temp.ipynb\n",
            " top3_contexts.csv\n",
            " train_data_10_percent_sample.csv\n",
            " train_data_aug_Backtranslation_EngtoGertoRuss.csv\n",
            " train_data_augWordNet.csv\n",
            " train_data_augWordNet.gsheet\n",
            " train_data_aug_WordSwapQWERTY.csv\n",
            " train_data.csv\n",
            " train_data_plus_DrQA_context.csv\n",
            " train_qs_charswap.csv\n",
            " train_qs_wordnet.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_XtEDEOqbUZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"df_train.csv\")\n",
        "#df= pd.read_csv(\"char_swap_fin.csv\")"
      ],
      "metadata": {
        "id": "scOPlz7qbY8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "pKikjpbpukMp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "991b2596-8e87-40f2-bd21-549147ab8588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0    title                                            context  \\\n",
              "0               0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "1               1  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "2               2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "3               3  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "4               4  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "...           ...      ...                                                ...   \n",
              "58851       58851   Matter  These quarks and leptons interact through four...   \n",
              "58852       58852   Matter  These quarks and leptons interact through four...   \n",
              "58853       58853   Matter  These quarks and leptons interact through four...   \n",
              "58854       58854   Matter  The term \"matter\" is used throughout physics i...   \n",
              "58855       58855   Matter  The term \"matter\" is used throughout physics i...   \n",
              "\n",
              "                                                question  answerable  \\\n",
              "0      Beyoncé When did Beyonce leave Destiny's Child...        True   \n",
              "1      Beyoncé What album made her a worldwide known ...        True   \n",
              "2         Beyoncé Who managed the Destiny's Child group?        True   \n",
              "3                 Beyoncé When did Beyoncé rise to fame?        True   \n",
              "4      Beyoncé What role did Beyoncé have in Destiny'...        True   \n",
              "...                                                  ...         ...   \n",
              "58851      Matter How many quarks and leptons are there?       False   \n",
              "58852  Matter What model satisfactorily explains grav...       False   \n",
              "58853  Matter Mass and energy can always be compared ...       False   \n",
              "58854  Matter Physics has broadly agreed on the defin...       False   \n",
              "58855  Matter What field of study has a variety of un...       False   \n",
              "\n",
              "               answer_text  answer_start  question_id  context_id  title_id  \n",
              "0                     2003         526.0            0           0         0  \n",
              "1      Dangerously in Love         505.0            1           0         0  \n",
              "2           Mathew Knowles         360.0            2           0         0  \n",
              "3               late 1990s         276.0            3           0         0  \n",
              "4              lead singer         290.0            4           0         0  \n",
              "...                    ...           ...          ...         ...       ...  \n",
              "58851                  NaN           NaN        75023       15553       360  \n",
              "58852                  NaN           NaN        75024       15553       360  \n",
              "58853                  NaN           NaN        75025       15553       360  \n",
              "58854                  NaN           NaN        75026       15554       360  \n",
              "58855                  NaN           NaN        75027       15554       360  \n",
              "\n",
              "[58856 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7756e6f0-6b50-4d31-b59f-1f1f1026b165\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answerable</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>question_id</th>\n",
              "      <th>context_id</th>\n",
              "      <th>title_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé When did Beyonce leave Destiny's Child...</td>\n",
              "      <td>True</td>\n",
              "      <td>2003</td>\n",
              "      <td>526.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé What album made her a worldwide known ...</td>\n",
              "      <td>True</td>\n",
              "      <td>Dangerously in Love</td>\n",
              "      <td>505.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé Who managed the Destiny's Child group?</td>\n",
              "      <td>True</td>\n",
              "      <td>Mathew Knowles</td>\n",
              "      <td>360.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé When did Beyoncé rise to fame?</td>\n",
              "      <td>True</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé What role did Beyoncé have in Destiny'...</td>\n",
              "      <td>True</td>\n",
              "      <td>lead singer</td>\n",
              "      <td>290.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58851</th>\n",
              "      <td>58851</td>\n",
              "      <td>Matter</td>\n",
              "      <td>These quarks and leptons interact through four...</td>\n",
              "      <td>Matter How many quarks and leptons are there?</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75023</td>\n",
              "      <td>15553</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58852</th>\n",
              "      <td>58852</td>\n",
              "      <td>Matter</td>\n",
              "      <td>These quarks and leptons interact through four...</td>\n",
              "      <td>Matter What model satisfactorily explains grav...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75024</td>\n",
              "      <td>15553</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58853</th>\n",
              "      <td>58853</td>\n",
              "      <td>Matter</td>\n",
              "      <td>These quarks and leptons interact through four...</td>\n",
              "      <td>Matter Mass and energy can always be compared ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75025</td>\n",
              "      <td>15553</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58854</th>\n",
              "      <td>58854</td>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Matter Physics has broadly agreed on the defin...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75026</td>\n",
              "      <td>15554</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58855</th>\n",
              "      <td>58855</td>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Matter What field of study has a variety of un...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75027</td>\n",
              "      <td>15554</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>58856 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7756e6f0-6b50-4d31-b59f-1f1f1026b165')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7756e6f0-6b50-4d31-b59f-1f1f1026b165 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7756e6f0-6b50-4d31-b59f-1f1f1026b165');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Question_list = df[\"question\"]#.tolist()"
      ],
      "metadata": {
        "id": "hXLP2aSA3P_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLPAttack"
      ],
      "metadata": {
        "id": "8xHRryePDyzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installation"
      ],
      "metadata": {
        "id": "Sw0OpaM1EWg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install textattack[tensorflow]"
      ],
      "metadata": {
        "id": "uge5o5uGbhOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26a7321-52ff-4f1f-947c-69ed39517fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textattack[tensorflow]\n",
            "  Downloading textattack-0.3.8-py3-none-any.whl (418 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.7/418.7 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (1.13.1+cu116)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (4.64.1)\n",
            "Collecting lru-dict\n",
            "  Downloading lru_dict-1.1.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (0.5.3)\n",
            "Collecting datasets==2.4.0\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 KB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (3.7)\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.9/401.9 KB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (1.21.6)\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting OpenHowNet\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pinyin==0.4.0\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (3.9.0)\n",
            "Collecting transformers>=4.21.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<8.1.0 in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (7.1.2)\n",
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Collecting bert-score>=0.3.5\n",
            "  Downloading bert_score-0.3.12-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (0.42.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (1.7.1)\n",
            "Collecting lemminflect\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 KB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (1.3.5)\n",
            "Requirement already satisfied: tensorflow-estimator==2.9.0 in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (2.9.0)\n",
            "Collecting tensorflow-text>=2\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.8/dist-packages (from textattack[tensorflow]) (0.12.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.4.0->textattack[tensorflow]) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.4.0->textattack[tensorflow]) (2022.11.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==2.4.0->textattack[tensorflow]) (21.3)\n",
            "Collecting dill<0.3.6\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.4.0->textattack[tensorflow]) (2.25.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.4.0->textattack[tensorflow]) (9.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (1.51.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (4.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (2.9.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (15.0.6.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (0.29.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->textattack[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bert-score>=0.3.5->textattack[tensorflow]) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->textattack[tensorflow]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->textattack[tensorflow]) (2022.7)\n",
            "Collecting tensorflow-text>=2\n",
            "  Downloading tensorflow_text-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.21.0->textattack[tensorflow]) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.21.0->textattack[tensorflow]) (2022.6.2)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from flair->textattack[tensorflow]) (1.0.2)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 KB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from flair->textattack[tensorflow]) (0.8.10)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia_API-0.5.8-py3-none-any.whl (13 kB)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from flair->textattack[tensorflow]) (3.6.0)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.8/dist-packages (from flair->textattack[tensorflow]) (4.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from flair->textattack[tensorflow]) (4.9.2)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown==4.4.0->flair->textattack[tensorflow]) (4.6.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->textattack[tensorflow]) (1.2.0)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree\n",
            "  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1->textattack[tensorflow]) (0.38.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.4.0->textattack[tensorflow]) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.4.0->textattack[tensorflow]) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.4.0->textattack[tensorflow]) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.4.0->textattack[tensorflow]) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.4.0->textattack[tensorflow]) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.4.0->textattack[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.4.0->textattack[tensorflow]) (4.0.2)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.4.0->flair->textattack[tensorflow]) (6.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.7->flair->textattack[tensorflow]) (3.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.7->flair->textattack[tensorflow]) (2.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.7->flair->textattack[tensorflow]) (0.16.0)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[tensorflow]) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[tensorflow]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[tensorflow]) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack[tensorflow]) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack[tensorflow]) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack[tensorflow]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack[tensorflow]) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->flair->textattack[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (2.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy->flair->textattack[tensorflow]) (0.2.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py38-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair->textattack[tensorflow]) (3.11.0)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->textattack[tensorflow]) (3.2.2)\n",
            "Building wheels for collected packages: pinyin, mpld3, pycld2, word2number, docopt, sqlitedict, langdetect, pptree, overrides\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630495 sha256=cfdf2a0f23dfda8849be07c838c7d93d322b021b3306d7b0eaa5234bf7fcc8fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/2a/d9/9c0f787a4d55f9a9eca26d322eafbe083bab41cb9bffb2e6e8\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=48a4a0a0531739cdd7f56a1266f2400195c70cf30d6ff59c90fe8acc85d67797\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/9f/9d/d806a20bd97bc7076d724fa3e69fa5be61836ba16b2ffa6126\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp38-cp38-linux_x86_64.whl size=9917409 sha256=3fd45fc65b3f3e75cb002dec5ce1304b10e914df78fd5729d6b3dc6879750b2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/3a/82/d990040cbe6c3527732e931e2925785e83fe9aaa5a11c313ca\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=76aed2f14380221f9226c4bced3d98b6a62300aac89ebf8c2a643b7fc72efb37\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/f3/5a/d88198fdeb46781ddd7e7f2653061af83e7adb2a076d8886d6\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=880b22c21eb001e3d490f5d9e266d603469bed955db7f6da8c9c374642d088fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16869 sha256=4622c2f35d3d8dbac3d960e7902b386d9615c72fdbf90aff46f55427f7725c1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/c6/16/46e174009277f9bccdaa7215a243939d2f70180804b249bf3a\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=43e503913a8a1c3eb38ce0960c4746ccec203f82a015cf8784b479e56ec8df9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=40b215dbaee0a9899452668549eebfd90b341c06d2a2de66b75dc8d873e228c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/8b/30/5b20240d3d13a9dfafb6a6dd49d1b541c86d39812cb3690edf\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=7520c0cdaf5b1857abcbeb34f2a62ea9c1c6cee49ba63d2323feaf3312b1644b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/4f/72/28857f75625b263e2e3f5ab2fc4416c0a85960ac6485007eaa\n",
            "Successfully built pinyin mpld3 pycld2 word2number docopt sqlitedict langdetect pptree overrides\n",
            "Installing collected packages: word2number, tokenizers, sqlitedict, sentencepiece, pycld2, py4j, pptree, pinyin, overrides, mpld3, lru-dict, janome, docopt, xxhash, urllib3, terminaltables, tensorboardX, segtok, num2words, markdown, lemminflect, langdetect, importlib-metadata, ftfy, dill, deprecated, conllu, anytree, multiprocess, hyperopt, wikipedia-api, responses, OpenHowNet, language-tool-python, konoha, huggingface-hub, bpemb, transformers, datasets, flair, bert-score, textattack, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.4.1\n",
            "    Uninstalling Markdown-3.4.1:\n",
            "      Successfully uninstalled Markdown-3.4.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.0.0\n",
            "    Uninstalling importlib-metadata-6.0.0:\n",
            "      Successfully uninstalled importlib-metadata-6.0.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed OpenHowNet-2.0 anytree-2.8.0 bert-score-0.3.12 bpemb-0.3.4 conllu-4.5.2 datasets-2.4.0 deprecated-1.2.13 dill-0.3.5.1 docopt-0.6.2 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.11.1 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 language-tool-python-2.7.1 lemminflect-0.2.3 lru-dict-1.1.8 markdown-3.3.4 mpld3-0.3 multiprocess-0.70.13 num2words-0.5.12 overrides-3.1.0 pinyin-0.4.0 pptree-3.1 py4j-0.10.9.7 pycld2-0.41 responses-0.18.0 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.1.0 tensorboardX-2.5.1 tensorflow-2.9.1 tensorflow-text-2.9.0 terminaltables-3.1.10 textattack-0.3.8 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.26.14 wikipedia-api-0.5.8 word2number-1.1 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import transformations, contraints, and the Augmenter\n",
        "from textattack.transformations import WordSwapRandomCharacterDeletion\n",
        "from textattack.transformations import WordSwapQWERTY\n",
        "from textattack.transformations import CompositeTransformation\n",
        "\n",
        "from textattack.constraints.pre_transformation import RepeatModification\n",
        "from textattack.constraints.pre_transformation import StopwordModification\n",
        "\n",
        "from textattack.augmentation import Augmenter"
      ],
      "metadata": {
        "id": "CcvlFC3rfZVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1648c9a6-d0e5-491e-c816-68c54715c07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Updating TextAttack package dependencies.\n",
            "textattack: Downloading NLTK required packages.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WordNet Augmenter"
      ],
      "metadata": {
        "id": "FIa5I8buhM3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textattack.augmentation import WordNetAugmenter\n",
        "augmenter = WordNetAugmenter()\n",
        "df['augmented_qs_wordnet'] = df.apply(lambda row: augmenter.augment(row.question), axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-PPFZTOkb3",
        "outputId": "626467da-8f06-4464-81ce-afd7cfef1fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['augmented_qs_wordnet']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue32B84aShz6",
        "outputId": "78ceb5b4-6d02-4ee7-f39e-119b42d47096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [Beyoncé When did Beyonce leave Destiny's Chil...\n",
              "1        [Beyoncé What album puddle her a worldwide kno...\n",
              "2        [Beyoncé Who managed the Destiny's Child aggro...\n",
              "3            [Beyoncé When did Beyoncé emanation to fame?]\n",
              "4        [Beyoncé What role did Beyoncé have in Destiny...\n",
              "                               ...                        \n",
              "58851     [subject How many quarks and leptons are there?]\n",
              "58852    [Matter What manakin satisfactorily explains g...\n",
              "58853    [Matter Mass and energy can e'er be compared t...\n",
              "58854    [affair Physics has broadly agreed on the defi...\n",
              "58855    [issue What field of study has a variety of un...\n",
              "Name: augmented_qs_wordnet, Length: 58856, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('train_data_plus_aug_WordNet.csv')"
      ],
      "metadata": {
        "id": "qjyTkt_8-Vc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKxp_m4i-VaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ukTgCd4_zu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PToCPMSZ_zsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WVitxjzD_zpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-LKn_zq_zmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Character Augmenter"
      ],
      "metadata": {
        "id": "lTvl7aEKhSR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up transformation using CompositeTransformation()\n",
        "transformation = CompositeTransformation([WordSwapQWERTY()])\n",
        "# Set up constraints\n",
        "constraints = [RepeatModification(), StopwordModification()]\n",
        "# Create augmenter with specified parameters\n",
        "augmenter = Augmenter(transformation=transformation, constraints=constraints, pct_words_to_swap=0.2, transformations_per_example=1)"
      ],
      "metadata": {
        "id": "FJad_vsAi71F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CharSwap(question):\n",
        "  try:\n",
        "    aug_qs = augmenter.augment(question)\n",
        "  except Exception as e:\n",
        "    return question\n",
        "    #augmented_question.append(question)\n",
        "  else:\n",
        "    return aug_qs[0]\n",
        "    #augmented_question.append(aug_qs[0])\n"
      ],
      "metadata": {
        "id": "dhN8H-oNjr-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['augmented_qs_charswap'] = df['question'].map(CharSwap)  ## Only Char Swap\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "fbvAb_KPCUIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('train_data_plus_aug_CharSwap.csv')"
      ],
      "metadata": {
        "id": "C0PT_pBRDAUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brVVR63eDJOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSzSqTheDJEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPi5OcLHDJB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['augmented_qs_wordnet_plus_charswap'] = df['augmented_qs_wordnet'].map(CharSwap)   ##Both Aug together\n",
        "display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "XwKxAFRAkVyg",
        "outputId": "5dec3b0e-40dc-4267-a20d-e2adcecbb529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Unnamed: 0    title                                            context  \\\n",
              "0           0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "1           1  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "2           2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "3           3  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "4           4  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "\n",
              "                                            question  answerable  \\\n",
              "0  Beyoncé When did Beyonce leave Destiny's Child...        True   \n",
              "1  Beyoncé What album made her a worldwide known ...        True   \n",
              "2     Beyoncé Who managed the Destiny's Child group?        True   \n",
              "3             Beyoncé When did Beyoncé rise to fame?        True   \n",
              "4  Beyoncé What role did Beyoncé have in Destiny'...        True   \n",
              "\n",
              "           answer_text  answer_start  question_id  context_id  title_id  \\\n",
              "0                 2003         526.0            0           0         0   \n",
              "1  Dangerously in Love         505.0            1           0         0   \n",
              "2       Mathew Knowles         360.0            2           0         0   \n",
              "3           late 1990s         276.0            3           0         0   \n",
              "4          lead singer         290.0            4           0         0   \n",
              "\n",
              "                                augmented_qs_wordnet  \\\n",
              "0  [Beyoncé When did Beyonce leave Destiny's Chil...   \n",
              "1  [Beyoncé What album puddle her a worldwide kno...   \n",
              "2  [Beyoncé Who managed the Destiny's Child aggro...   \n",
              "3      [Beyoncé When did Beyoncé emanation to fame?]   \n",
              "4  [Beyoncé What role did Beyoncé have in Destiny...   \n",
              "\n",
              "                  augmented_qs_wordnet_plus_charswap  \n",
              "0  [Beyoncé When did Beyonce leave Destiny's Chil...  \n",
              "1  [Beyoncé What album puddle her a worldwide kno...  \n",
              "2  [Beyoncé Who managed the Destiny's Child aggro...  \n",
              "3      [Beyoncé When did Beyoncé emanation to fame?]  \n",
              "4  [Beyoncé What role did Beyoncé have in Destiny...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c88063a4-3c29-44d5-8337-62e517930d39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answerable</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>question_id</th>\n",
              "      <th>context_id</th>\n",
              "      <th>title_id</th>\n",
              "      <th>augmented_qs_wordnet</th>\n",
              "      <th>augmented_qs_wordnet_plus_charswap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé When did Beyonce leave Destiny's Child...</td>\n",
              "      <td>True</td>\n",
              "      <td>2003</td>\n",
              "      <td>526.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé When did Beyonce leave Destiny's Chil...</td>\n",
              "      <td>[Beyoncé When did Beyonce leave Destiny's Chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé What album made her a worldwide known ...</td>\n",
              "      <td>True</td>\n",
              "      <td>Dangerously in Love</td>\n",
              "      <td>505.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé What album puddle her a worldwide kno...</td>\n",
              "      <td>[Beyoncé What album puddle her a worldwide kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé Who managed the Destiny's Child group?</td>\n",
              "      <td>True</td>\n",
              "      <td>Mathew Knowles</td>\n",
              "      <td>360.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé Who managed the Destiny's Child aggro...</td>\n",
              "      <td>[Beyoncé Who managed the Destiny's Child aggro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé When did Beyoncé rise to fame?</td>\n",
              "      <td>True</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé When did Beyoncé emanation to fame?]</td>\n",
              "      <td>[Beyoncé When did Beyoncé emanation to fame?]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé What role did Beyoncé have in Destiny'...</td>\n",
              "      <td>True</td>\n",
              "      <td>lead singer</td>\n",
              "      <td>290.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé What role did Beyoncé have in Destiny...</td>\n",
              "      <td>[Beyoncé What role did Beyoncé have in Destiny...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c88063a4-3c29-44d5-8337-62e517930d39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c88063a4-3c29-44d5-8337-62e517930d39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c88063a4-3c29-44d5-8337-62e517930d39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.drop(['augmented_qs_wordnet'], axis=1)\n",
        "\n",
        "##Do this only if both Aug together needed else save each aug column individually- only WordNet, only CharSwap, Both Togeteher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "34Yef48nJAQ1",
        "outputId": "8bcd0399-3a4a-4a74-90de-22ececbb175c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0    title                                            context  \\\n",
              "0               0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "1               1  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "2               2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "3               3  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "4               4  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "...           ...      ...                                                ...   \n",
              "58851       58851   Matter  These quarks and leptons interact through four...   \n",
              "58852       58852   Matter  These quarks and leptons interact through four...   \n",
              "58853       58853   Matter  These quarks and leptons interact through four...   \n",
              "58854       58854   Matter  The term \"matter\" is used throughout physics i...   \n",
              "58855       58855   Matter  The term \"matter\" is used throughout physics i...   \n",
              "\n",
              "                                                question  answerable  \\\n",
              "0      Beyoncé When did Beyonce leave Destiny's Child...        True   \n",
              "1      Beyoncé What album made her a worldwide known ...        True   \n",
              "2         Beyoncé Who managed the Destiny's Child group?        True   \n",
              "3                 Beyoncé When did Beyoncé rise to fame?        True   \n",
              "4      Beyoncé What role did Beyoncé have in Destiny'...        True   \n",
              "...                                                  ...         ...   \n",
              "58851      Matter How many quarks and leptons are there?       False   \n",
              "58852  Matter What model satisfactorily explains grav...       False   \n",
              "58853  Matter Mass and energy can always be compared ...       False   \n",
              "58854  Matter Physics has broadly agreed on the defin...       False   \n",
              "58855  Matter What field of study has a variety of un...       False   \n",
              "\n",
              "               answer_text  answer_start  question_id  context_id  title_id  \\\n",
              "0                     2003         526.0            0           0         0   \n",
              "1      Dangerously in Love         505.0            1           0         0   \n",
              "2           Mathew Knowles         360.0            2           0         0   \n",
              "3               late 1990s         276.0            3           0         0   \n",
              "4              lead singer         290.0            4           0         0   \n",
              "...                    ...           ...          ...         ...       ...   \n",
              "58851                  NaN           NaN        75023       15553       360   \n",
              "58852                  NaN           NaN        75024       15553       360   \n",
              "58853                  NaN           NaN        75025       15553       360   \n",
              "58854                  NaN           NaN        75026       15554       360   \n",
              "58855                  NaN           NaN        75027       15554       360   \n",
              "\n",
              "                      augmented_qs_wordnet_plus_charswap  \n",
              "0      [Beyoncé When did Beyonce leave Destiny's Chil...  \n",
              "1      [Beyoncé What album puddle her a worldwide kno...  \n",
              "2      [Beyoncé Who managed the Destiny's Child aggro...  \n",
              "3          [Beyoncé When did Beyoncé emanation to fame?]  \n",
              "4      [Beyoncé What role did Beyoncé have in Destiny...  \n",
              "...                                                  ...  \n",
              "58851   [subject How many quarks and leptons are there?]  \n",
              "58852  [Matter What manakin satisfactorily explains g...  \n",
              "58853  [Matter Mass and energy can e'er be compared t...  \n",
              "58854  [affair Physics has broadly agreed on the defi...  \n",
              "58855  [issue What field of study has a variety of un...  \n",
              "\n",
              "[58856 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3dd66e34-4714-43bf-904f-0c105f7027f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answerable</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>question_id</th>\n",
              "      <th>context_id</th>\n",
              "      <th>title_id</th>\n",
              "      <th>augmented_qs_wordnet_plus_charswap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé When did Beyonce leave Destiny's Child...</td>\n",
              "      <td>True</td>\n",
              "      <td>2003</td>\n",
              "      <td>526.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé When did Beyonce leave Destiny's Chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé What album made her a worldwide known ...</td>\n",
              "      <td>True</td>\n",
              "      <td>Dangerously in Love</td>\n",
              "      <td>505.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé What album puddle her a worldwide kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé Who managed the Destiny's Child group?</td>\n",
              "      <td>True</td>\n",
              "      <td>Mathew Knowles</td>\n",
              "      <td>360.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé Who managed the Destiny's Child aggro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé When did Beyoncé rise to fame?</td>\n",
              "      <td>True</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé When did Beyoncé emanation to fame?]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Beyoncé What role did Beyoncé have in Destiny'...</td>\n",
              "      <td>True</td>\n",
              "      <td>lead singer</td>\n",
              "      <td>290.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Beyoncé What role did Beyoncé have in Destiny...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58851</th>\n",
              "      <td>58851</td>\n",
              "      <td>Matter</td>\n",
              "      <td>These quarks and leptons interact through four...</td>\n",
              "      <td>Matter How many quarks and leptons are there?</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75023</td>\n",
              "      <td>15553</td>\n",
              "      <td>360</td>\n",
              "      <td>[subject How many quarks and leptons are there?]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58852</th>\n",
              "      <td>58852</td>\n",
              "      <td>Matter</td>\n",
              "      <td>These quarks and leptons interact through four...</td>\n",
              "      <td>Matter What model satisfactorily explains grav...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75024</td>\n",
              "      <td>15553</td>\n",
              "      <td>360</td>\n",
              "      <td>[Matter What manakin satisfactorily explains g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58853</th>\n",
              "      <td>58853</td>\n",
              "      <td>Matter</td>\n",
              "      <td>These quarks and leptons interact through four...</td>\n",
              "      <td>Matter Mass and energy can always be compared ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75025</td>\n",
              "      <td>15553</td>\n",
              "      <td>360</td>\n",
              "      <td>[Matter Mass and energy can e'er be compared t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58854</th>\n",
              "      <td>58854</td>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Matter Physics has broadly agreed on the defin...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75026</td>\n",
              "      <td>15554</td>\n",
              "      <td>360</td>\n",
              "      <td>[affair Physics has broadly agreed on the defi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58855</th>\n",
              "      <td>58855</td>\n",
              "      <td>Matter</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Matter What field of study has a variety of un...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75027</td>\n",
              "      <td>15554</td>\n",
              "      <td>360</td>\n",
              "      <td>[issue What field of study has a variety of un...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>58856 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dd66e34-4714-43bf-904f-0c105f7027f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3dd66e34-4714-43bf-904f-0c105f7027f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3dd66e34-4714-43bf-904f-0c105f7027f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('train_qs_all_augmentation.csv')"
      ],
      "metadata": {
        "id": "oYIbwUiunFRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLoHR8uiJmcC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}